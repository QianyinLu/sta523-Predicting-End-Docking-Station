---
title: "Homework 6"
author: 'Steven Winter, Zining Ma, Qianyin Lu, Mengxuan Cui'
date: "11/14/2019"
output: 
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE,
                      warning = FALSE)
```

## Preliminaries

We need the following packages:
```{r packages}
library(tidyverse)
library(vroom)
#devtools::install_github("tidyverse/multidplyr")
# make sure all other packages are up to date first
library(multidplyr)
library(lubridate)
library(data.table)
library(profvis)
```

## Task 1

We're going to use the code from the class to load the data in parallel. Here we create a cluster with 4 nodes and tell ``R`` to split up loading these 5 files over the four nodes. Ideally this would be done over five nodes, but we were not allowed to use more than four.
```{r loaddata}
base_url = "http://www2.stat.duke.edu/~sms185/data/bike/"
files = c("cbs_2013.csv", "cbs_2014.csv", "cbs_2015.csv", "cbs_2016.csv", "cbs_2017.csv")

cbs_names = c("duration", "start_date", "end_date", "start_station_number", 
               "start_station","start_station_number", "start_station", 
               "bike_number","member_type")

# code from slides
clust <- multidplyr::new_cluster(4)
multidplyr::cluster_assign_partition(clust, file_name = paste0(base_url, files))
multidplyr::cluster_send(clust, cbs_data <- vroom::vroom(file_name))
cbs <- multidplyr::party_df(clust, "cbs_data")
```

We will now use ``rename()`` to replace the current column names with the names from ``cbs_test.csv``. This will make it easier to filter the data later on.
```{r rename}
cbs = cbs %>%
  dplyr::rename(duration = Duration,
         start_date = `Start date`,
         end_date = `End date`,
         start_station_number = `Start station number`,
         start_station = `Start station`,
         end_station_number = `End station number`,
         end_station = `End station`,
         member_type = `Member type`,
         bike_number = `Bike number`)
```

We'll also leverage the cluster to create columns for year, month, day, and hour. These will be used for filtering later.
```{r addcols}
cbs = cbs %>% mutate(year = lubridate::year(start_date),
                     month = lubridate::month(start_date),
                     day = lubridate::day(start_date),
                     hour = lubridate::hour(start_date),
                     # wday returns 2~6 for Monday~Friday
                     weekday = lubridate::wday(start_date) %in% 2:6)
```

That is all of the preprocessing we need to do. Now we will move the data back to our machine wiht ``collect()`` and convert it to a ``data.table``. The main advantage of data tables is they allow the user to set binary search keys, which makes filtering the data dramatically faster than filtering a data frame. 
```{r collect}
cbs_dt = data.table(collect(cbs))
```

We have to add the weather data before we set any search keys. API limitations forced us to gather all of the weather data in advance - below is the code we used to produce ``weather.Rds``. 
```{r getweather}
# need to add the code here, probably set eval to false?
```

We don't believe that cyclists care if the weather is clear or partly cloudy; nor do we think there's much of a difference between their behaviour in heavy rain or heavy snow. This leads us to create coarsely binned categories for weather conditions. This new column is added alongside temperature to the data table created above based on time.
```{r addweather}
weather = readRDS("weather.rds")

weat_cond = weather %>% 
  select(year,month,day,hour,weekday,icon,temperature) %>% 
  #weekday 1~5 are Monday~Friday
  mutate(weekday = weekday %in% 1:5,
         icon = recode(icon,
                       `clear-day` = "nice",
                       `clear-night` = "nice",
                       `cloudy` = "nice",
                       `fog` = "bad",
                       `partly-cloudy-day` = "nice",
                       `partly-cloudy-night` = "nice",
                       `rain` = "terrible",
                       `sleet` = "terrible",
                       `snow` = "terrible"))

cbs_dt = merge(cbs_dt,weat_cond,all.x=T,sort = F)
```

We can finally set keys:
```{r keys}
setkey(cbs_dt, start_station, duration, end_station)
```

As mentioned before, this will make searching by ``start_station``, `duration`, or `end_station` very fast.

## Task 2:

Our goal is to beat uniform predictions. To us, the most immediate flaw with uniform predictions is they assign a nonzero probability to stops the cyclist could not have possibly reached in a given duration. Given a test row it seems reasonable to filter out data table to a set of rows with the same `start_station` and similar durations. We can then assign the empirical probability to the end stops in this subset of the data: for example, if there are 30 unique end stations and `A` appears $10$ times then we would set $P(\text{end_station}=A|\text{data})=10/30$. Any end stations not in this subset will be assigned a probability of zero. 

### Helper Functions
Obviously, this method requires us to quickly generate a data table with similar rows. The next helper function does exactly that.

```{r similarrows}
get_similar_rows <- function(row, input_dt, duration_minus = 0.2,duration_plus=0.2,
                             month_delta = 2, hour_delta=2, temp_delta = 10) {
  # filter the data.table to rows with:
  # - the same start station
  # - durations in [1-duration_delta, 1+duration_delta]*actual_duration
  # - months within +- month_delta
  # - hours withim +- hour delta
  
  
  same_start = cbs_dt[J(row$start_station), nomatch=0L]
  
  same_start[T
             & duration %between% c((1-duration_minus)*row$duration, (1+duration_plus)*row$duration)
             #& abs(month - row$month)<= month_delta
             & abs(hour-row$hour) <= hour_delta
             & weekday == row$weekday
             #& icon == row$icon
             #& abs(temperature - row$temperature) <= temp_delta
             ]
}
```

The next step is to assign the empirical probabilitiy to each row. Example: If there are 400 posible stops and stop j appears 18 times in the list of similar rows then we would set p(end_stop = stop_j|data) = 18/400/ If stop k does not appear in the similar rows then we set p(end_stop = stop_k|data) = 0. **Could also just try assigning a uniform probability to these.**
```{r calculateprobs}
make_predictions <- function(similar_rows, all_stops) {
  # takes in a list of similar rows
  # assigns each unique stop the observed probability
  # assigns any missing stops zero probability
  
  nonzero_probs = as.data.frame(table(similar_rows$end_station)/nrow(similar_rows))
  predictions = spread(nonzero_probs, key=Var1, value=Freq)
  
  zero_probs = all_stops[!(all_stops %in% names(predictions))]
  predictions[zero_probs] = 0
  
  predictions
}

```

**Also need a fast helper function to join these together. Maybe mcapply or something? I just have a simple wrapper for now. Sorting the columns too for faster binding later. Currently handling outliers by using the precomputed naive probability. We can do better.**

```{r wrapper}
prediction_wrapper = function(row, input_dt, features, all_stops, ordered_names) {
  # takes in a row from the test_set
  # computes and appends predictions
  
  similar_rows = get_similar_rows(row, input_dt)
  
  if(nrow(similar_rows)==0){
    # if there are are no similar rows in our data, just guess
    return(row[,ordered_names])
  }
  
  # compute and append predictions
  predictions = make_predictions(similar_rows, all_stops)
  output_row = cbind(row[features], predictions)
  
  # return everything in the same order to make rbind faster
  output_row[,ordered_names]
}
```


### Testing
Need to load the test data and include weather condition. **We should add weather to the test data in the next code chunk:**
```{r loadtest}
test_set = vroom::vroom("http://www2.stat.duke.edu/~sms185/data/bike/cbs_test.csv")
test_wet = test_set %>% mutate(year = lubridate::year(start_date),
                               month = lubridate::month(start_date),
                               day = lubridate::day(start_date),
                               hour = lubridate::hour(start_date),
                               # wday returns 2~6 for Monday~Friday
                               weekday = lubridate::wday(start_date) %in% 2:6)
test_wet = merge(test_wet,weat_cond,all.x = T,sort = F) %>% arrange(start_date)
```

Get extra information to pass to the helper functions:
```{r names}
ordered_names = names(test_set)

exclude_features = c("year","month","day","hour","weekday","icon","temperature")
ordered_names = ordered_names[!(ordered_names %in% exclude_features)]
features = c("start_date","end_date","duration","start_station_number",
                  "start_station","bike_number", "member_type")
all_stops = names(test_set)[!(names(test_set) %in% c(features,exclude_features))]
```
Finally, run our functions on the entire thing.

**Currently only running on part of the data.**

```{r predictall}
final_predictions = plyr::adply(test_wet, 1, function(x) prediction_wrapper(x, cbs_dt, features, all_stops, ordered_names),
                           .progress = "text")
final_predictions = final_predictions %>% select(-exclude_features)
#write_csv(final_predictions, "cbs_git-r-done.csv")
```

Save these results:
```{r save}
write_csv(final_predictions, "cbs_git-r-done.csv")
```

**This is writing the times incorrectly and adding row names...Maybe still has a month column too? Not sure how to fix this right now.**

## Model selection

In our final model, we use these conditions:

1. $|hour_{sample}-hour_{pred}|<=2$

2. $duration_{sample}\in[0.8*duration_{pred},1.2*duration_{pred}]$

3. $weekday_{sample}$ and $weekday_{pred}$ are both in {Monday~Friday} or {Sunday,Saturday}

How we choose our model is described detailed below:

We started from a model which considers condition $\Delta_{month}\leq2$, $\Delta_{hour}\leq2$, $\Delta_{duration}\leq20\%$, and this model gave us score=5.61.

Then we thought weather and weekday may affect people's choice, so we 

1. integrated weather data: temperature and icon, which has values {nice,bad,terrible}

2. add weekday indicator: with values TRUE: weekday is in Monday~Friday, and FALSE: weekday is Sunday or Saturday.

We combined temperature, icon and weekday into above setting, and got a terrible score=3.75.

Then we tried combinations of new variables and got following results:

1. weekday+temperature(change $\leq$ 7):5.23

2. weekday+icon:5.43

3. weekday only:5.77

(We didn't exclude weekday because we think it really matters)

It's a shock that adding new variables more than weekday is making the score worse. We guess the reason is that, adding variables is reducing our filtered sample too much that the given prediction can not capture the whole picture.

So we changed our direction: what will happed if we add very little conditions?

We tried two setting:

1. only weekday indicator, no month,hour,duration and weather, and got a score=1.97

2. no condition at all, completely naive prediction based on whole data, and got score 1.90

Comparision between these attempts and those above, it shows that duration and time really matters.

And then we chose a model as:

$\Delta_{duration}\leq20\%$, $\Delta_{hour}\leq2$, $\Delta{temperature}\leq7$ and consider weekday.

We have hour here but month not because We think time in a day is much more important than month, and information of month is mainly season, which could be replaced by temperature. This setting gave us a highest score 5.85 at that time.

Then based on this setting, we tried more adjustment:

1. change $\Delta_{duration}\leq20\%$ to $\Delta_{duration}\in[-50\%,20\%]$ and $\Delta_{duration}\in[-20\%,50\%]$ and got score 5.03 and 5.40 respectively. It shows that our previous setting $\Delta_{duration}\leq20\%$ is a good intuitive choice.

2. change $\Delta_{temperature}\leq7$ to $\Delta_{temperature}\leq5$ and $\Delta_{temperature}\leq10$ and got score 5.65 and 6.02 respectively. It shows that larger range of temperature give more precise prediction. 

3. so We tried next model excluding temperature, and got a amazing score 6.15.

This final model including conditions $\Delta_{duration}\leq20\%$, 
$\Delta_{hour}\leq2$ and weekday indicator is our best model. And the process we got here showes that time is a sigificant factor and weather doesn't matter.
